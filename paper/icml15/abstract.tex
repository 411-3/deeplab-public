\begin{abstract}
Deep convolutional neural networks (DCNNs) trained on a large number
of images with strong pixel-level annotations have recently
significantly pushed the state-of-art in semantic image
segmentation. We study the more challenging problem of learning DCNNs
for semantic image segmentation from either (1) weakly annotated
training data such as bounding boxes or image-level labels or (2) a
combination of few strongly labeled and many weakly labeled images,
sourced from one or multiple datasets.
%% We propose a modified EM algorithm
%% featuring a biased E-step which takes into account the weak labels
%% when inferring the latent training image segmentations.
We develop methods for semantic image segmentation model training
under these weakly supervised and semi-supervised settings. Extensive
experimental evaluation shows that the proposed techniques can learn
models delivering state-of-art results on the challenging PASCAL VOC
2012 image segmentation benchmark, while requiring significantly less
annotation effort.
\end{abstract}

 %%% Local Variables:
 %%% mode: latex
 %%% TeX-master: "top.tex"
 %%% End:
