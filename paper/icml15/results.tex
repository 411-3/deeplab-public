\section{Experimental Evaluation}
\paragraph{Dataset} Our proposed models are evaluated on the PASCAL VOC 2012 segmentation benchmark \citep{everingham2014pascal}, consisting of 20 foreground object classes and one background class. The performance is measured in terms of pixel intersection-over-union (IOU) averaged across the 21 classes. The original PASCAL VOC 2012 dataset contains $1464$, $1449$, and $1456$ images for training, validation, and test, respectively. We use the extra annotations provided by \citet{hariharan2011semantic}, resulting in $10,582$ training images. We also take use of the abundant annotations provided by the MS-COCO dataset \citep{lin2014microsoft}, which contains $123,287$ images in the trainval set. MS-COCO dataset currently has $80$ foreground object classes and one background class.

\paragraph{Training} Our proposed models are built on top of the ``DeepLab'' and ``DeepLab-CRF'' models proposed by \citep{chen2014semantic}, which is composed of two main components: DCNN and Dense Conditional Random Field (DenseCRF) \citep{krahenbuhl2011efficient}. Similarly, we adopt piecewise training, decoupling the DCNN and CRF training stages, assuming the unary terms provided by the DCNN are fixed during CRF training. 

For DCNN training we employ the VGG-16 netwok which has been pre-trained on ImageNet. We fine-tuned the VGG-16 network on the VOC 21-way classification task by stochastic gradient descent on the cross-entropy loss function. Generally, we use a mini-batch of 20 images and initial learning rate of $0.001$ ($0.01$ for the final classifier layer), multiplying the learning rate by 0.1 at every 3000 iterations. We use momentum of $0.9$ and a weight decay of $0.0005$.

After the DCNN has been fine-tuned, we cross-validate the parameters of the Dense CRF model. The cross-validation is performed on a small subset of the validation set (we use 100 images). We use 10 iterations for the efficient mean field inference algorithm \citep{krahenbuhl2011efficient}.

\paragraph{Weak annotations} In order to simulate the situations where only weak annotations are available and to have fair comparisons (e.g., use the same images for all settings), we generate the weak annotations from the pixel-level annotations. The image-level labels are easily generated by summarizing the pixel-level annotations, while the bounding box annotations are produced by drawing rectangles for each object instance (PASCAL VOC 2012 also provides instance-level annotations) in the dataset.

\subsection{Evaluation on Validation set}
The evaluations of our proposed models are mainly conducted on the PASCAL official validation set. 

\paragraph{Pixel Annotations} Training the models with full pixel annotatins are considered as a strong upper bound on the models trained with weak annotations. We first try to reproduce the results of DeepLab and DeepLab-CRF \citep{chen2014semantic} by using only PASCAL VOC augmented training set. We then exploited the rich annotations provided by MS-COCO dataset: the models are fine-tuned on PASCAL VOC after fine-tuning on MS-COCO. As shown in Tab.~\ref{tb:pixel_annot}, training the models with a large amount of full annotations further improves both DeepLab and DeepLab-CRF by about $4\%$ on the validation set.

\begin{table}
  \centering
  \caption{{\bf{Pixel Annotations.}} Performance on the PASCAL VOC 2012 `val' set. First column, and second column show the number of strongly labeled images from PASCAL and MS-COCO. }
  \begin{tabular}{| c | c | c | c |}
    \hline
    \# PASCAL & \# MS-COCO & DeepLab & DeepLab-CRF \\
    \hline
    10,582 &   0     & 59.85 & 63.93  \\
    \hline
    10,582 & 123,287 & 64.51 & 67.98 \\
    \hline
    \end{tabular}
  \label{tb:pixel_annot}
\end{table}

\paragraph{Bounding Box Annotations} Given bounding box annotations, our first baseline method (denoted as Bbox-Baseline) estimates the pixel-level ground-truth segmentation by assigning the same foreground class label to all the pixels within the particular bounding box. The estimation is performed from larger bounding box to smaller one so that the smaller objects are not fully occluded by the larger ones. Another approach we employ is adopting Dense CRF to estimate the segmentation within the crude bounding box (denoted as Bbox-DenseCRF). We keep eroding the bounding box mask until $K\%$ pixels are left. The center ($K\%$) pixels of the bounding box are treated as positive examples for the respective object class, while pixels outside the bounding box are considered as background class. The Dense CRF is then applied to infer the label for pixels in between. We conduct an experiment to see how many center pixels should be used as positive examples on the held-out 100 images. As shown in Tab.~\ref{tb:bbox_erosion}, using only $20\%$ center pixels results in highly accurate ground truth estimation ($72.59\%$). Using more than $20\%$ center pixels degrades the performance due to the highly deformable object shapes in the dataset. Some estimated segmentations by both approaches are shown in Fig.~\ref{fig:bbox_illustration}. We then apply this tuned Dense CRF to estimate the ground-truth segmentation for all the bounding boxes in the dataset. The validation result is summarized in Tab.~\ref{tb:bbox_annot}, which shows that both DeepLab and DeepLab-CRF trained with the segmenation generated by Bbox-DenseCRF can achieve about $6\%$ better performance than Bbox-Baseline.

\begin{table}
  \centering
  \caption{{\bf{Bbox-DenseCRF preprocessing analysis on the held-out 100 images.}}}
  \begin{tabular}{c | c}
    Amount of Center pixels & pixel IOU (\%) \\
    \hline
    \hline
    80\%  & 65.59 \\
    60\%  & 68.80 \\
    40\%  & 71.82 \\
    20\%  & 72.59 \\
    \end{tabular}
  \label{tb:bbox_erosion}
\end{table}

\begin{figure}
  \centering
  \begin{tabular}{c c c c}
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/img/2010_004063.jpg} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/gt/2010_004063.png} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/bbox/2010_004063.png} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/crf/2010_004063.png} \\    
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/img/2009_000219.jpg} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/gt/2009_000219.png} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/bbox/2009_000219.png} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/crf/2009_000219.png} \\        \includegraphics[width=0.21\linewidth]{fig/erode_bbox/img/2009_002382.jpg} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/gt/2009_002382.png} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/bbox/2009_002382.png} & 
    \includegraphics[width=0.21\linewidth]{fig/erode_bbox/crf/2009_002382.png} \\    
    {\scriptsize Image with Bbox} & {\scriptsize Ground-Truth} & {\scriptsize Bbox-Baseline} & {\scriptsize Bbox-DenseCRF}
  \end{tabular}
  \caption{{\bf Segmentation estimation for bounding box annotations.} We show three examples from easy to hard.}
  \label{fig:bbox_illustration}
\end{figure}

\begin{table}
  \centering
  \caption{{\bf Bounding Box Annotations.} Performance on the PASCAL VOC 2012 `val' set. DeepLab and DeeLab-CRF are trained with the segmentation generated by Bbox-Baseline or Bbox-DenseCRF.}
  \begin{tabular}{| l | c | c |}
    \hline
     & DeepLab & DeepLab-CRF \\
    \hline
    Bbox-Baseline & 47.72 & 52.52 \\ 
    \hline
    Bbox-DenseCRF & 53.68 & 58.45 \\
    \hline
    \end{tabular}
  \label{tb:bbox_annot}
\end{table}

\paragraph{Image Annotatins}

\paragraph{Pixel+Image Annotations}

\paragraph{Comparison with State-of-art} We herein compare our proposed models with other state-of-art methods in the context of weakly supervised learning. We list in Tab.~\ref{tab:weak_state_of_art_val} the comparable methods side-by-side. The methods proposed by \citet{pinheiro2014weakly} are prefixed by ``Idiap-''. Our proposed methods consistently outperformed their methods. Our DeepLab-Weak is comparable to their Idiap-base, which are trained with only weak labels. Image-Level-Prior (ILP) is incorporated into their base model, similar to our DeepLab-Adaweak which dynamically weights DCNN score maps w.r.t. weak labels. To smooth the prediction results, they proposed to use (1) superpixels (denoted as sppxl) or (2) region proposals (denoted as seg). The superpixel smoothing is similar to the Dense CRF we employed, both trying to model the long-range correlation between pixels. The region proposal algorithm (MCG \citep{arbelaez2014multiscale}) they employed are elaborate smoothing method, which has been trained on thousands of fully annotated images. On the other hand, our proposed method Deeplab-CRF-StrongWeak shows that our model can attain much better results by directly training the models with both strong and weak annotations.

Note that the method proposed by \citet{pathak2014fully} achieves $20.46\%$ on PASCAL VOC 2011 validation set (a subset of VOC 2012).

\paragraph{Training time} Fine-tuning our network on PASCAL VOC 2012 takes about 10
hours on a NVIDIA Tesla K40 GPU. All our implementations are based on the public available source Caffe \citep{jia2014caffe}.

\paragraph{Qualitative results} We provide visual comparisons between our proposed models in Fig.~\ref{fig:ValResults}. The results with exploiting only weak labels (DeepLab-CRF-Adaweak) are relatively noisy compared to other methods. Training the model with only Bbox-Baseline (DeepLab-CRF-Bbox-Baseline) gives very crude results, while the results from the model (DeepLab-CRF-Bbox-DenseCRF) trained with the estimated segmentation by Bbox-DenseCRF are visually better. Jointly training the model (DeepLab-CRF-StrongWeak) with a small number of full annotations and many weak annotations can further improve the results qualitatively. The results from the model (DeepLab-CRF-COCO) trained with both strong annotations from PASCAL and MS-COCO are the best.

\begin{table}
  \centering
  \caption{{\bf Comparison with state-of-art methods on val set.}}
  \begin{tabular}{l|c}
    {\bf Method} & pixel IOU (\%) \\
    \hline \hline
    Idiap-base   & 17.8 \\
    DeepLab-Weak & 20.3 \\
    \hline \hline
    Idiap-base+ILP  & 32.6 \\
    DeepLab-Adaweak & 34.2 \\
    \hline \hline
    Idiap-base+ILP+sppxl & 36.6 \\
    DeepLab-CRF-Adaweak  & 38.2 \\
    \hline \hline
    Idiap-base+ILP+seg       & 42.0 \\
    DeepLab-CRF-StrongWeak   & 61.9 \\
  \end{tabular}
  \label{tab:weak_state_of_art_val}
\end{table}

\subsection{Evaluation on Test set}
After setting the model choices on the validation set, we evaluate our variant models on the PASCAL VOC 2012 official test set. The results from our models along with other state-of-art models are listed in Tab.~\ref{tab:voc2012}. 

Given only weak labels, our DeepLab-CRF-Adaweak is better than Idiap-base+ILP+sppxl \citep{pinheiro2014weakly}. 

In the context of bounding box annotations, training our models with the segmentation inferred by Bbox-DenseCRF is $6.2\%$ better than with crude segmentation from Bbox-Baseline. Note that our DeepLab-CRF-Bbox-DenseCRF is comparable to other fully supervised models, such as Hypercolumn-SDS \citep{hariharan2014hypercolumns}.

Our DeepLab-CRF-StrongWeak takes use of both strong and weak annotations during training. DeepLab-CRF-StrongWeak1 exploits 1464 fully annotated images (PASCAL train set), while DeepLab-CRF-StrongWeak2 uses 2913 fully annotated images (PASCAL trainval set). DeepLab-CRF-StrongWeak1 has better performance (absolute $22.9\%$ improvement) than Idap-base+ILP+reg, showing that directly leveraging fully annotated images during training is better than resorting to some region proposal algorithms. Note that DeepLab-CRF-StrongWeak2 delivers the same performance as DeepLab-CRF \citep{chen2014semantic}, which is trained with about 12K fully annotated images. Furthermore, our DeepLab-CRF-StrongWeak2 outperforms many fully supervised models, including TTI-Zoomout-16 \citep{mostajabi2014feedforward}, FCN-8s \citep{long2014fully}, and MSRA-CFM \citep{dai2014convolutional}.

Last, our DeepLab-CRF-COCO is fine-tuned on MS-COCO dataset before fine-tuning on PASCAL augmented trainval set. This model sets a new state-of-art result.



\begin{table}[t]
  \centering
  \caption{{\bf Pixel+Image Annotations.} }
  \scalebox{0.8}{
  %\addtolength{\tabcolsep}{-2.0pt}
  \begin{tabular}{|c|c|c|c|}
    \hline
    {\bf Weak} & {\bf Strong} & \multirow{2}{*}{DeepLab} & \multirow{2}{*}{DeepLab-CRF}\\
    \cline{1-2}
    \# PASCAL & \# PASCAL & & \\
    \hline
    10,582   &    0    & 20.25  & 20.77   \\
    \hline
    10,582   &    0    & 34.22* & 38.23*  \\
    \hline
    10,382   &  200    & 44.05  & 47.57   \\
    \hline
    10,082   &  500    & 52.52  & 56.89   \\
    \hline
    9,832    &  750    & 55.04  & 58.82   \\
    \hline
    9,582    &  1,000  & 56.79  & 60.48   \\
    \hline
      0      &  1,464  & 54.77  & 57.62   \\
    \hline
    5,000    &  1,464  & 57.02  & 60.48   \\
    \hline
    9,118    &  1,464  & {\bf 58.30}  & {\bf 61.90}   \\
    \hline
  \end{tabular}  
  }
  \label{tab:strong_weak_annot}
\end{table}

\begin{table}[t]
  \centering
  \caption{{\bf Pixel+Image Annotations with MS-COCO.} }
  \scalebox{0.77}{
  %\addtolength{\tabcolsep}{-2.0pt}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    {\bf Weak} & \multicolumn{2}{c|}{\bf Strong} & \multirow{2}{*}{DeepLab} & \multirow{2}{*}{DeepLab-CRF}\\
    \cline{1-3}
    \# MS-COCO & \# PASCAL & \# MS-COCO & & \\
    \hline
      0       & 10,582 & 0       & 59.85 & 63.93 \\
    \hline
      123,287 & 10,582 & 0       & 60.41 & 64.44 \\
    \hline
      0       & 10,582 & 5,000   & ?     &  ?    \\
    \hline
      118,287 & 10,582 & 5,000   & ?     &  ?    \\
    \hline    
      0       & 10,582 & 123,287 & 64.51 & 67.98 \\
    \hline
  \end{tabular}  
  }
  \label{tab:strong_weak_annot_coco}
\end{table}


\begin{figure*}[!htbp]
  \centering
  %\vspace{-1.cm}
  \scalebox{0.82} {
  \begin{tabular}{c c c c c c}
    %\addtolength{\tabcolsep}{-6.5pt}
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/img/2007_000042.jpg} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/adaweak/2007_000042.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox/2007_000042.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox_crf/2007_000042.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/strongweak/2007_000042.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/cocomix/2007_000042.png} \\
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/img/2007_002852.jpg} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/adaweak/2007_002852.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/bbox/2007_002852.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/bbox_crf/2007_002852.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/strongweak/2007_002852.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/cocomix/2007_002852.png} \\
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/img/2007_003022.jpg} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/adaweak/2007_003022.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox/2007_003022.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox_crf/2007_003022.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/strongweak/2007_003022.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/cocomix/2007_003022.png} \\
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/img/2008_003546.jpg} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/adaweak/2008_003546.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/bbox/2008_003546.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/bbox_crf/2008_003546.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/strongweak/2008_003546.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/cocomix/2008_003546.png} \\
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/img/2008_004363.jpg} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/adaweak/2008_004363.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/bbox/2008_004363.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/bbox_crf/2008_004363.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/strongweak/2008_004363.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/cocomix/2008_004363.png} \\
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/img/2009_001299.jpg} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/adaweak/2009_001299.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox/2009_001299.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox_crf/2009_001299.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/strongweak/2009_001299.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/cocomix/2009_001299.png} \\
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/img/2010_004994.jpg} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/adaweak/2010_004994.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/bbox/2010_004994.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/bbox_crf/2010_004994.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/strongweak/2010_004994.png} &
    \includegraphics[height=0.123\linewidth]{fig/val_crf_vis/cocomix/2010_004994.png} \\
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/img/2011_002322.jpg} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/adaweak/2011_002322.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/bbox/2011_002322.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/bbox_crf/2011_002322.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/strongweak/2011_002322.png} &
    \includegraphics[height=0.122\linewidth]{fig/val_crf_vis/cocomix/2011_002322.png} \\
    \includegraphics[height=0.13\linewidth]{fig/val_crf_vis/img/2007_001630.jpg} &
    \includegraphics[height=0.13\linewidth]{fig/val_crf_vis/adaweak/2007_001630.png} &
    \includegraphics[height=0.13\linewidth]{fig/val_crf_vis/bbox/2007_001630.png} &
    \includegraphics[height=0.13\linewidth]{fig/val_crf_vis/bbox_crf/2007_001630.png} &
    \includegraphics[height=0.13\linewidth]{fig/val_crf_vis/strongweak/2007_001630.png} &
    \includegraphics[height=0.13\linewidth]{fig/val_crf_vis/cocomix/2007_001630.png} \\
    \includegraphics[height=0.15\linewidth]{fig/val_crf_vis/img/2007_005331.jpg} &
    \includegraphics[height=0.15\linewidth]{fig/val_crf_vis/adaweak/2007_005331.png} &
    \includegraphics[height=0.15\linewidth]{fig/val_crf_vis/bbox/2007_005331.png} &
    \includegraphics[height=0.15\linewidth]{fig/val_crf_vis/bbox_crf/2007_005331.png} &
    \includegraphics[height=0.15\linewidth]{fig/val_crf_vis/strongweak/2007_005331.png} &
    \includegraphics[height=0.15\linewidth]{fig/val_crf_vis/cocomix/2007_005331.png} \\
\hline \hline
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/img/2007_000830.jpg} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/adaweak/2007_000830.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox/2007_000830.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox_crf/2007_000830.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/strongweak/2007_000830.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/cocomix/2007_000830.png} \\
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/img/2007_001175.jpg} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/adaweak/2007_001175.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox/2007_001175.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/bbox_crf/2007_001175.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/strongweak/2007_001175.png} &
    \includegraphics[height=0.11\linewidth]{fig/val_crf_vis/cocomix/2007_001175.png} \\
    {\scriptsize Image} & {\scriptsize DeepLab-CRF-Adaweak} & {\scriptsize DeepLab-CRF-Bbox-Baseline} & {\scriptsize DeepLab-CRF-Bbox-DenseCRF} & {\scriptsize DeepLab-CRF-StrongWeak} & {\scriptsize DeepLab-CRF-COCO} \\
  \end{tabular}
  }
  %\vspace{-0.3cm}
  \caption{Visualization results on VOC 2012-val. For each row, we show the input image, the segmentation result delivered by adaweak, bbox, bbox-crf, strongweak, coco. The results are refined by DenseCRF. We show difficult examples in the last two rows.} 
  \label{fig:ValResults}
\end{figure*}





{\color{blue} REMEMBER to put the links (test results) in the supplementary material if main paper has no space.}
\begin{table*}[ht]\scriptsize
 \caption{Pixel IoU (\%) on the PASCAL VOC 2012 test set, using the trainval set for training.}
\setlength{\tabcolsep}{3pt}
%\hspace{-1.8cm}
\resizebox{2.1\columnwidth}{!}{
\begin{tabular}{|l||c*{20}{|c}||c|}
\hline 
Method          & bkg &  aero & bike & bird & boat & bottle& bus & car  &  cat & chair& cow  &table & dog  & horse & mbike& person& plant&sheep& sofa &train & tv   & mean \\
\hline \hline
Idiap-base+ILP+sppxl      & 74.7 & 38.8 & 19.8 & 27.5 & 21.7 & 32.8 & 40.0 & 50.1 & 47.1 & 7.2 & 44.8 & 15.8 & 49.4 & 47.3 & 36.6 & 36.4 & 24.3 & 44.5 & 21.0 & 31.5 & 41.3 & 35.8 \\
Idiap-base+ILP+seg        & 78.7 & 48.0 & 21.2 & 31.1 & 28.4 & 35.1 & 51.4 & 55.5 & 52.8 & 7.8 & 56.2 & 19.9 & 53.8 & 50.3 & 40.0 & 38.6 & 27.8 & 51.8 & 24.7 & 33.3 & 46.3 & 40.6 \\
\hline \hline
Hypercolumn-SDS & 88.9 & 68.4 & 27.2 & 68.2 & 47.6 & 61.7 & 76.9 & 72.1 & 71.1 & 24.3 & 59.3 & 44.8 & 62.7 & 59.4 & 73.5 & 70.6 & 52.1 & 63.0 & 38.1 & 60.0 & 54.1 & 59.2 \\   
MSRA-CFM        & -    & 75.7 & 26.7 & 69.5 & 48.8 & 65.6 & 81.0 & 69.2 & 73.3 & 30.0 & 68.7 & 51.5 & 69.1 & 68.1 & 71.7 & 67.5 & 50.4 & 66.5 & 44.4 & 58.9 & 53.5 & 61.8 \\
FCN-8s          & -    & 76.8 & 34.2 & 68.9 & 49.4 & 60.3 & 75.3 & 74.7 & 77.6 & 21.4 & 62.5 & 46.8 & 71.8 & 63.9 & 76.5 & 73.9 & 45.2 & 72.4 & 37.4 & 70.9 & 55.1 & 62.2 \\
TTI-Zoomout-16  & 89.8 & 81.9 & 35.1 & 78.2 & 57.4 & 56.5 & 80.5 & 74.0 & 79.8 & 22.4 & 69.6 & 53.7 & 74.0 & 76.0 & 76.6 & 68.8 & 44.3 & 70.2 & 40.2 & 68.9 & 55.3 & 64.4 \\
DeepLab-CRF     & 92.1 & 78.4 & 33.1 & 78.2 & 55.6 & 65.3 & 81.3 & 75.5 & 78.6 & 25.3 & 69.2 & 52.7 & 75.2 & 69.0 & 79.1 & 77.6 & 54.7 & 78.3 & 45.1 & 73.3 & 56.2 & 66.4 \\ 
\hline \hline
DeepLab-CRF-Adaweak & 76.4 & 37.0 & 17.6 & 38.2 & 26.6 & 37.1 & 51.9 & 43.3 & 48.1 & 16.8 & 44.6 & 27.9 & 46.5 & 46.2 & 46.6 & 30.3 & 28.9 & 42.0 & 30.0 & 43.8 & 39.3 & 39.0 \\
DeepLab-CRF-Bbox-Baseline    & 82.9 & 43.6 & 22.5 & 50.5 & 45.0 & 62.5 & 76.0 & 66.5 & 61.2 & 25.3 & 55.8 & 52.1 & 56.6 & 48.1 & 60.1 & 58.2 & 49.5 & 58.3 & 40.7 & 62.3 & 61.1 & 54.2 \\
DeepLab-CRF-Bbox-DenseCRF    & 89.9 & 69.3 & 28.2 & 71.9 & 43.4 & 59.7 & 74.3 & 69.0 & 76.7 & 23.5 & 64.6 & 47.1 & 71.0 & 64.0 & 72.8 & 72.4 & 50.4 & 72.0 & 40.2 & 63.4 & 44.5 & 60.4 \\
DeepLab-CRF-StrongWeak1(1.5K) & 91.4 & 77.3 & 38.2 & 73.9 & 47.6 & 57.9 & 80.0 & 76.4 & 74.7 & 22.8 & 70.0 & 42.0 & 70.9 & 71.9 & 79.1 & 70.7 & 47.8 & 77.1 & 36.1 & 68.1 & 59.8 & 63.5 \\
DeepLab-CRF-StrongWeak2(3K) & 92.3 & 81.3 & {\bf 43.8} & 78.3 & 50.2 & 60.4 & 81.2 & 77.5 & 77.5 & 26.8 & 70.8 & 47.0 & 74.8 & 73.0 & 80.8 & 76.0 & 50.8 & 78.0 & 39.7 & 72.9 & 60.9 & 66.4 \\
DeepLabe-CRF-COCO & {\bf 93.2} & {\bf 85.3} & 36.2 & {\bf 84.8} & {\bf 61.2} & {\bf 67.5} & {\bf 84.7} & {\bf 81.4} & {\bf 81.0} & {\bf 30.8} & {\bf 73.8} & {\bf 53.8} & {\bf 77.5} & {\bf 76.5} & {\bf 82.3} & {\bf 81.6} & {\bf 56.3} & {\bf 78.9} & {\bf 52.3} & {\bf 76.6} & {\bf 63.3} & {\bf 70.4} \\
\hline
 \end{tabular}
} \label{tab:voc2012}
\end{table*}
