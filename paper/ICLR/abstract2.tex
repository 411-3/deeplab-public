\newcommand{\mycomment}[1]{}
\begin{abstract}
 Deep Convolutional Neural Networks (DCNN) have decisevely pushed the envelope of  high-level vision over the last couple of years. However, their applications to low-level tasks are often still not up the level of  computer vision systems using simple classifiers with well-engineered features. This is likely due to the increased invariance of DCNNs to local image transformations;  in this work we aim at  handling the effects of this invariance in the context of semantic segmetnation.

Our main contribution consists in  increasing the spatial acuity of DCNNs  by combining their invariant classification results with  image-based segmentation cues. 
We first demonstrate that simple modifications to the standard architectures used for object classification can deliver impessively accurate dense labelling results while operating at XXX frames-per-seconds. We then couple DCNNs  with Mean Field inference for Markov Random Fields and obtain state-of-the-art results on the PASCAL semantic image segmentation task.  

\mycomment{We consider our main contribution to be the increase of the acuity of DCNNs, by combining invariant classifications with bottom-up, image-driven cues for segmentation.} 
\end{abstract}

