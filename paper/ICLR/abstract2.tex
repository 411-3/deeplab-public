%\newcommand{\mycomment}[1]{}
\begin{abstract}
  Deep Convolutional Neural Networks (DCNNs) have recently shown state of the
  art performance in high level vision tasks, such as image classification and
  object detection. This work brings together methods from DCNNs and
  probabilistic graphical models for addressing the task of per-pixel
  classification (also called ''semantic segmentation''). We show that
  responses at the final layer of DCNNs are not sufficiently localized for
  accurate object segmentation. This is due to the very invariance properties
  that make DCNNs good for high level tasks. We overcome this poor
  localization property of deep networks by combining the responses at the
  final DCNN layer with a fully connected Conditional Random Field (CRF).
  Qualitatively, our method is able to localize segment boundaries at a level
  of accuracy which is beyond previous method. Quantitatively, our system sets
  the new state-of-art at the PASCAL VOC-2012 semantic image segmentation
  task, reaching 66.4\% IOU accuracy in the test set. We show how these
  results can be obtained efficiently. Careful network re-purposing and a
  novel application of the 'hole' algorithm from the wavelet community allow
  dense computation of neural net responses at 8 frames per second on a modern
  GPU.

%  Deep Convolutional Neural Networks (DCNN) have decisively pushed the
%  envelope of high-level vision over the last couple of years. However, their
%  applications to low-level tasks are often still not up the level of computer
%  vision systems using simple classifiers with well-engineered features. This
%  is likely due to the increased invariance of DCNNs to local image
%  transformations; in this work we aim at handling the effects of this
%  invariance in the context of semantic segmentation.

%  Our main contribution consists in increasing the spatial acuity of DCNNs by
%  combining their invariant classification results with image-based
%  segmentation cues.  We first demonstrate that simple modifications to the
%  standard architectures used for object classification can deliver
%  impressively accurate dense labeling results while operating at 8
%  frames-per-seconds. We then couple DCNNs with Mean Field inference for
%  Markov Random Fields and obtain state-of-the-art results on the PASCAL
%  semantic image segmentation task.

%\mycomment{We consider our main contribution to be the increase of the acuity of DCNNs, by combining invariant classifications with bottom-up, image-driven cues for segmentation.} 
\end{abstract}

